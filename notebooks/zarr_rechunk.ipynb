{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rechunk_to_zarr(ds, chunks, path):\n",
    "    rechunked_ds = ds.chunk(chunks=chunks)\n",
    "    for var_name in rechunked_ds.variables:\n",
    "        var = rechunked_ds[var_name]\n",
    "        chunksizes = tuple(chunks[dim_name] if dim_name in chunks else var.shape[var.dims.index(dim_name)] for dim_name in var.dims)\n",
    "        var.encoding.update({\"chunks\": chunksizes})\n",
    "    rechunked_ds.to_zarr(path, mode=\"w\")\n",
    "    return rechunked_ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(\"D:\\\\BC\\\\xcubes\\\\dcs4cop_xcube_OLCI_2017050_land_masked_testing_xarray_upgrade.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:         (bnds: 2, lat: 5632, lon: 10240, time: 40)\n",
       "Coordinates:\n",
       "  * lat             (lat) float64 62.67 62.66 62.66 62.66 62.65 62.65 62.65 ...\n",
       "    lat_bnds        (lat, bnds) float64 dask.array<shape=(5632, 2), chunksize=(5632, 2)>\n",
       "  * lon             (lon) float64 -16.0 -16.0 -15.99 -15.99 -15.99 -15.99 ...\n",
       "    lon_bnds        (lon, bnds) float64 dask.array<shape=(10240, 2), chunksize=(10240, 2)>\n",
       "  * time            (time) datetime64[ns] 2017-05-01T09:45:02.296853760 ...\n",
       "    time_bnds       (time, bnds) datetime64[ns] dask.array<shape=(40, 2), chunksize=(1, 2)>\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    chl_c2rcc       (time, lat, lon) float64 dask.array<shape=(40, 5632, 10240), chunksize=(1, 5632, 10240)>\n",
       "    kd_z90max       (time, lat, lon) float64 dask.array<shape=(40, 5632, 10240), chunksize=(1, 5632, 10240)>\n",
       "    tsm_c2rcc       (time, lat, lon) float64 dask.array<shape=(40, 5632, 10240), chunksize=(1, 5632, 10240)>\n",
       "    tur_nechad_665  (time, lat, lon) float64 dask.array<shape=(40, 5632, 10240), chunksize=(1, 5632, 10240)>\n",
       "    tur_nechad_865  (time, lat, lon) float64 dask.array<shape=(40, 5632, 10240), chunksize=(1, 5632, 10240)>\n",
       "Attributes:\n",
       "    acknowledgment:             ESA Sentinel-3 OLCI data, EU HIGHROC project\n",
       "    comment:                    \n",
       "    contributor_name:           \n",
       "    contributor_role:           \n",
       "    creator_email:              info@brockmann-consult.de\n",
       "    creator_name:               Brockmann Consult GmbH\n",
       "    creator_url:                https://www.brockmann-consult.de\n",
       "    date_modified:              2019-01-18T15:29:24.123503\n",
       "    geospatial_lat_max:         62.666666666666664\n",
       "    geospatial_lat_min:         48.0\n",
       "    geospatial_lat_resolution:  0.002604166666666666\n",
       "    geospatial_lat_units:       degrees_north\n",
       "    geospatial_lon_max:         10.666666666666664\n",
       "    geospatial_lon_min:         -16.0\n",
       "    geospatial_lon_resolution:  0.0026041666666666665\n",
       "    geospatial_lon_units:       degrees_east\n",
       "    history:                    xcube/reproj-snap-nc\n",
       "    id:                         dcs4cop-olci-l2c-sns-b298-34a7-df87-98fe\n",
       "    institution:                Brockmann Consult GmbH\n",
       "    keywords:                   \n",
       "    license:                    terms and conditions of the DCS4COP data dist...\n",
       "    naming_authority:           bc\n",
       "    processing_level:           L2C\n",
       "    project:                    DCS4COP\n",
       "    publisher_email:            info@brockmann-consult.de\n",
       "    publisher_name:             Brockmann Consult GmbH\n",
       "    publisher_url:              https://www.brockmann-consult.de\n",
       "    references:                 https://cordis.europa.eu/project/rcn/212442_e...\n",
       "    source:                     Sentinel-3 OLCI L2 surface observation\n",
       "    standard_name_vocabulary:   \n",
       "    summary:                    \n",
       "    title:                      DCS4COP Sentinel-3 OLCI L2C Data Cube"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Specified zarr chunks (14, 704, 640) would overlap multiple dask chunks ((14, 14, 12), (704, 704, 704, 704, 704, 704, 704, 704), (640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640)). This is not implemented in xarray yet.  Consider rechunking the data using `chunk()` or specifying different chunks in encoding.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-e3102dd2d66b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrechunk_to_zarr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m704\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"D:\\\\BC\\\\xcubes\\\\dcs4cop_xcube_OLCI_2017050_14_704_640.zarr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-156-baf78a0f1ece>\u001b[0m in \u001b[0;36mrechunk_to_zarr\u001b[1;34m(ds, chunks, path)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mchunksizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdim_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunks\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdim_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"chunks\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mchunksizes\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mrechunked_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_zarr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrechunked_ds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\xcube-dev\\lib\\site-packages\\xarray\\core\\dataset.py\u001b[0m in \u001b[0;36mto_zarr\u001b[1;34m(self, store, mode, synchronizer, group, encoding, compute)\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_zarr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m         return to_zarr(self, store=store, mode=mode, synchronizer=synchronizer,\n\u001b[1;32m-> 1187\u001b[1;33m                        group=group, encoding=encoding, compute=compute)\n\u001b[0m\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__unicode__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\xcube-dev\\lib\\site-packages\\xarray\\backends\\api.py\u001b[0m in \u001b[0;36mto_zarr\u001b[1;34m(dataset, store, mode, synchronizer, group, encoding, compute)\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[1;31m# I think zarr stores should always be sync'd immediately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[1;31m# TODO: figure out how to properly handle unlimited_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m     \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_to_store\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msync\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\xcube-dev\\lib\\site-packages\\xarray\\core\\dataset.py\u001b[0m in \u001b[0;36mdump_to_store\u001b[1;34m(self, store, encoder, sync, encoding, unlimited_dims, compute)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1074\u001b[0m         store.store(variables, attrs, check_encoding,\n\u001b[1;32m-> 1075\u001b[1;33m                     unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[0;32m   1076\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m             \u001b[0mstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\xcube-dev\\lib\\site-packages\\xarray\\backends\\zarr.py\u001b[0m in \u001b[0;36mstore\u001b[1;34m(self, variables, attributes, *args, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         AbstractWritableDataStore.store(self, variables, attributes,\n\u001b[1;32m--> 337\u001b[1;33m                                         *args, **kwargs)\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\xcube-dev\\lib\\site-packages\\xarray\\backends\\common.py\u001b[0m in \u001b[0;36mstore\u001b[1;34m(self, variables, attributes, check_encoding_set, unlimited_dims)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_dimensions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munlimited_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munlimited_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         self.set_variables(variables, check_encoding_set,\n\u001b[1;32m--> 374\u001b[1;33m                            unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\xcube-dev\\lib\\site-packages\\xarray\\backends\\common.py\u001b[0m in \u001b[0;36mset_variables\u001b[1;34m(self, variables, check_encoding_set, unlimited_dims)\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_encoding_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             target, source = self.prepare_variable(\n\u001b[1;32m--> 411\u001b[1;33m                 name, v, check, unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\xcube-dev\\lib\\site-packages\\xarray\\backends\\zarr.py\u001b[0m in \u001b[0;36mprepare_variable\u001b[1;34m(self, name, variable, check_encoding, unlimited_dims)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         encoding = _extract_zarr_variable_encoding(\n\u001b[1;32m--> 321\u001b[1;33m             variable, raise_on_invalid=check_encoding)\n\u001b[0m\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0mencoded_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\xcube-dev\\lib\\site-packages\\xarray\\backends\\zarr.py\u001b[0m in \u001b[0;36m_extract_zarr_variable_encoding\u001b[1;34m(variable, raise_on_invalid)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     chunks = _determine_zarr_chunks(encoding.get('chunks'), variable.chunks,\n\u001b[1;32m--> 177\u001b[1;33m                                     variable.ndim)\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[0mencoding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chunks'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\xcube-dev\\lib\\site-packages\\xarray\\backends\\zarr.py\u001b[0m in \u001b[0;36m_determine_zarr_chunks\u001b[1;34m(enc_chunks, var_chunks, ndim)\u001b[0m\n\u001b[0;32m    136\u001b[0m                         \u001b[1;34m\" Consider rechunking the data using \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                         \u001b[1;34m\"`chunk()` or specifying different chunks in encoding.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                         % (enc_chunks_tuple, var_chunks))\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0menc_chunks_tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Specified zarr chunks (14, 704, 640) would overlap multiple dask chunks ((14, 14, 12), (704, 704, 704, 704, 704, 704, 704, 704), (640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640)). This is not implemented in xarray yet.  Consider rechunking the data using `chunk()` or specifying different chunks in encoding."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "rechunk_to_zarr(ds, dict(time=14, lat=704, lon=640), \"D:\\\\BC\\\\xcubes\\\\dcs4cop_xcube_OLCI_2017050_14_704_640.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(\"D:\\\\BC\\\\xcubes\\\\dcs4cop_xcube_OLCI_2017050_14_704_640.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:         (bnds: 2, lat: 5632, lon: 10240, time: 40)\n",
       "Coordinates:\n",
       "  * lat             (lat) float64 62.67 62.66 62.66 62.66 62.65 62.65 62.65 ...\n",
       "    lat_bnds        (lat, bnds) float64 dask.array<shape=(5632, 2), chunksize=(704, 2)>\n",
       "  * lon             (lon) float64 -16.0 -16.0 -15.99 -15.99 -15.99 -15.99 ...\n",
       "    lon_bnds        (lon, bnds) float64 dask.array<shape=(10240, 2), chunksize=(640, 2)>\n",
       "  * time            (time) datetime64[ns] 2017-05-01T09:45:02.296853760 ...\n",
       "    time_bnds       (time, bnds) datetime64[ns] dask.array<shape=(40, 2), chunksize=(1, 2)>\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    chl_c2rcc       (time, lat, lon) float64 dask.array<shape=(40, 5632, 10240), chunksize=(1, 704, 640)>\n",
       "    kd_z90max       (time, lat, lon) float64 dask.array<shape=(40, 5632, 10240), chunksize=(1, 704, 640)>\n",
       "    tsm_c2rcc       (time, lat, lon) float64 dask.array<shape=(40, 5632, 10240), chunksize=(1, 704, 640)>\n",
       "    tur_nechad_665  (time, lat, lon) float64 dask.array<shape=(40, 5632, 10240), chunksize=(1, 704, 640)>\n",
       "    tur_nechad_865  (time, lat, lon) float64 dask.array<shape=(40, 5632, 10240), chunksize=(1, 704, 640)>\n",
       "Attributes:\n",
       "    acknowledgment:             ESA Sentinel-3 OLCI data, EU HIGHROC project\n",
       "    comment:                    \n",
       "    contributor_name:           \n",
       "    contributor_role:           \n",
       "    creator_email:              info@brockmann-consult.de\n",
       "    creator_name:               Brockmann Consult GmbH\n",
       "    creator_url:                https://www.brockmann-consult.de\n",
       "    date_modified:              2019-01-18T15:29:24.123503\n",
       "    geospatial_lat_max:         62.666666666666664\n",
       "    geospatial_lat_min:         48.0\n",
       "    geospatial_lat_resolution:  0.002604166666666666\n",
       "    geospatial_lat_units:       degrees_north\n",
       "    geospatial_lon_max:         10.666666666666664\n",
       "    geospatial_lon_min:         -16.0\n",
       "    geospatial_lon_resolution:  0.0026041666666666665\n",
       "    geospatial_lon_units:       degrees_east\n",
       "    history:                    xcube/reproj-snap-nc\n",
       "    id:                         dcs4cop-olci-l2c-sns-b298-34a7-df87-98fe\n",
       "    institution:                Brockmann Consult GmbH\n",
       "    keywords:                   \n",
       "    license:                    terms and conditions of the DCS4COP data dist...\n",
       "    naming_authority:           bc\n",
       "    processing_level:           L2C\n",
       "    project:                    DCS4COP\n",
       "    publisher_email:            info@brockmann-consult.de\n",
       "    publisher_name:             Brockmann Consult GmbH\n",
       "    publisher_url:              https://www.brockmann-consult.de\n",
       "    references:                 https://cordis.europa.eu/project/rcn/212442_e...\n",
       "    source:                     Sentinel-3 OLCI L2 surface observation\n",
       "    standard_name_vocabulary:   \n",
       "    summary:                    \n",
       "    title:                      DCS4COP Sentinel-3 OLCI L2C Data Cube"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
